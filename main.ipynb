{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import shutil\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import subprocess \n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import easyocr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# ============ VietOCR hiện không sử dụng, chờ fine tune ==========\n",
    "# from vietocr.tool.predictor import Predictor\n",
    "# from vietocr.tool.config import Cfg\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "from transformers import AutoImageProcessor, TableTransformerForObjectDetection\n",
    "from ultralytics import YOLO # Giữ lại nếu YOLO_ENABLE_VALIDATION là True\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from tkinter import Tk, filedialog \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- Hàm thay thế cho cv2_imshow của Colab ---\n",
    "def cv2_imshow_local(img_array, window_name=\"Image\"):\n",
    "    # Lựa chọn 1: Lưu file tạm (như code gốc)\n",
    "    # cv2.imwrite(\"temp_display_image.png\", img_array)\n",
    "    # print(\"Ảnh được lưu vào temp_display_image.png\")\n",
    "\n",
    "    # Lựa chọn 2: Hiển thị trong cửa sổ (cần môi trường GUI)\n",
    "    #cv2.imshow(window_name, img_array)\n",
    "    #cv2.waitKey(1) # Đợi một chút để cửa sổ cập nhật, 0 là đợi phím bất kỳ\n",
    "    return\n",
    "# --- Kiểm tra Poppler ---\n",
    "# pdf2image cần có poppler. Hàm này để check PATH, nếu không có thì cần add.\n",
    "try:\n",
    "    convert_from_path(None) # gọi hàm dummy check poppler\n",
    "except Exception as e:\n",
    "    if \"poppler\" in str(e).lower():\n",
    "        print(\"Không có Poppler. pdf2image không hoạt động.\")\n",
    "        print(\"Cần cài Poppler và add vào PATH hệ thống.\")\n",
    "        sys.exit(\"Dừng do thiếu Poppler.\") \n",
    "    # else:\n",
    "    #     print(f\"Lỗi không xác định với pdf2image: {e}\") # Lỗi khác không phải poppler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_start_time = time.time()\n",
    "SHOW_PROCESSING_IMAGES: bool = False # Đặt False/True để hiển thị ảnh giữa process\n",
    "\n",
    "DEFAULT_FONT = None\n",
    "font_paths_to_try = [\"DejaVuSans-Bold.ttf\", \"arial.ttf\", \"arialbd.ttf\", \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"]\n",
    "for font_path_item in font_paths_to_try:\n",
    "    try:\n",
    "        DEFAULT_FONT = ImageFont.truetype(font_path_item, 12)\n",
    "        break\n",
    "    except IOError:\n",
    "        continue\n",
    "if DEFAULT_FONT is None:\n",
    "    DEFAULT_FONT = ImageFont.load_default()\n",
    "\n",
    "def display_image(title: str, image_np: np.ndarray, max_width: int = 800) -> None:\n",
    "    if not SHOW_PROCESSING_IMAGES or image_np is None or image_np.size == 0:\n",
    "        return\n",
    "    h_orig, w_orig = image_np.shape[:2]\n",
    "    display_img_resized = image_np\n",
    "    if w_orig > max_width:\n",
    "        scale = max_width / w_orig\n",
    "        new_h = int(h_orig * scale)\n",
    "        display_img_resized = cv2.resize(image_np, (max_width, new_h), interpolation=cv2.INTER_AREA)\n",
    "    # print(f\"\\n--- Đang hiển thị: {title} (Đã thay đổi kích thước nếu >{max_width}px chiều rộng) ---\")\n",
    "    # cv2_imshow_local(display_img_resized, title) # Sử dụng hàm local\n",
    "    # time.sleep(0.01) # Có thể không cần thiết với cv2.imshow và waitKey(1)\n",
    "\n",
    "def display_image_with_bboxes(\n",
    "    title: str, image_np: np.ndarray,\n",
    "    cv_bbox_abs: tuple[int, int, int, int] | None = None,\n",
    "    tt_bbox_abs: tuple[int, int, int, int] | None = None,\n",
    "    max_width: int = 800\n",
    ") -> None:\n",
    "    if not SHOW_PROCESSING_IMAGES or image_np is None or image_np.size == 0: return\n",
    "    display_img_pil = Image.fromarray(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(display_img_pil)\n",
    "    if cv_bbox_abs:\n",
    "        x, y, w, h = cv_bbox_abs\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=\"blue\", width=3)\n",
    "        draw.text((x + 2, y + 2), \"CV Contour\", fill=\"blue\", font=DEFAULT_FONT)\n",
    "    if tt_bbox_abs:\n",
    "        x, y, w, h = tt_bbox_abs\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=\"red\", width=3)\n",
    "        draw.text((x + 2, y - 15 if y > 15 else y + h + 2), \"TT Match\", fill=\"red\", font=DEFAULT_FONT)\n",
    "    display_img_np_annotated = cv2.cvtColor(np.array(display_img_pil), cv2.COLOR_RGB2BGR)\n",
    "    display_image(title, display_img_np_annotated, max_width)\n",
    "\n",
    "def display_processed_crop(title: str, processed_crop_np: np.ndarray, max_width: int = 800) -> None:\n",
    "    if not SHOW_PROCESSING_IMAGES or processed_crop_np is None or processed_crop_np.size == 0: return\n",
    "    display_image(title, processed_crop_np, max_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model_global: 'YOLO | None' = None\n",
    "yolo_device_global: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "yolo_model_classes_global: dict[int, str] = {}\n",
    "\n",
    "def load_yolo_model_safe(model_path_or_id: str, device: str) -> tuple['YOLO | None', dict[int, str]]:\n",
    "    global yolo_model_classes_global\n",
    "    loaded_model_local: 'YOLO | None' = None\n",
    "    model_classes_local: dict[int, str] = {}\n",
    "    try:\n",
    "        from ultralytics import YOLO \n",
    "        loaded_model_local = YOLO(model_path_or_id)\n",
    "        loaded_model_local.to(device)\n",
    "        dummy_img = np.zeros((64, 64, 3), dtype=np.uint8)\n",
    "        _ = loaded_model_local(dummy_img, device=(0 if device == 'cuda' else 'cpu'), verbose=False)\n",
    "        if hasattr(loaded_model_local, 'names') and loaded_model_local.names:\n",
    "            raw_names = loaded_model_local.names\n",
    "            if isinstance(raw_names, dict): model_classes_local = {int(k): v for k, v in raw_names.items() if str(k).isdigit()}\n",
    "            elif isinstance(raw_names, (list, tuple)): model_classes_local = {i: name for i, name in enumerate(raw_names)}\n",
    "        yolo_model_classes_global = model_classes_local\n",
    "    except ImportError:\n",
    "        print(\"LỖI: Không thể nhập thư viện ultralytics. YOLO sẽ không khả dụng.\")\n",
    "        loaded_model_local = None\n",
    "        yolo_model_classes_global = {}\n",
    "    except Exception as e_yolo_load:\n",
    "        print(f\"LỖI: Không thể tải mô hình YOLO '{model_path_or_id}': {e_yolo_load}\")\n",
    "        loaded_model_local = None\n",
    "        yolo_model_classes_global = {}\n",
    "    return loaded_model_local, model_classes_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"Sử dụng thiết bị: {DEVICE}\")\n",
    "\n",
    "# --- EasyOCR Reader ---\n",
    "EASYOCR_READER = None\n",
    "try:\n",
    "    EASYOCR_READER = easyocr.Reader(['vi'], gpu=(DEVICE == \"cuda\"))\n",
    "except Exception as e:\n",
    "    EASYOCR_READER = None\n",
    "\n",
    "# --- Detection Model ---\n",
    "TT_DETECTION_PROCESSOR = None\n",
    "TT_DETECTION_MODEL = None\n",
    "try:\n",
    "    TT_DETECTION_MODEL_NAME = \"microsoft/table-transformer-detection\"\n",
    "    TT_DETECTION_PROCESSOR = AutoImageProcessor.from_pretrained(TT_DETECTION_MODEL_NAME)\n",
    "    TT_DETECTION_MODEL = TableTransformerForObjectDetection.from_pretrained(TT_DETECTION_MODEL_NAME)\n",
    "    if TT_DETECTION_MODEL:\n",
    "        TT_DETECTION_MODEL.to(DEVICE)\n",
    "        TT_DETECTION_MODEL.eval()\n",
    "except Exception as e:\n",
    "    print(f\"LỖI khi tải mô hình Table Transformer (Detection): {e}\")\n",
    "    TT_DETECTION_MODEL = None\n",
    "    TT_DETECTION_PROCESSOR = None\n",
    "\n",
    "\n",
    "TT_STRUCTURE_PROCESSOR = None \n",
    "TT_STRUCTURE_MODEL = None\n",
    "try:\n",
    "\n",
    "    TT_STRUCTURE_MODEL_NAME = \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "    TT_STRUCTURE_PROCESSOR = AutoImageProcessor.from_pretrained(TT_STRUCTURE_MODEL_NAME)\n",
    "    TT_STRUCTURE_MODEL = TableTransformerForObjectDetection.from_pretrained(TT_STRUCTURE_MODEL_NAME)\n",
    "    if TT_STRUCTURE_MODEL:\n",
    "        TT_STRUCTURE_MODEL.to(DEVICE)\n",
    "        TT_STRUCTURE_MODEL.eval()\n",
    "except Exception as e:\n",
    "    print(f\"LỖI khi tải mô hình Table Transformer (Structure Recognition): {e}\")\n",
    "    TT_STRUCTURE_MODEL = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#            *** CÁC HÀM PERSPECTIVE WARP ***\n",
    "# ==============================================================================\n",
    "def order_points(pts: np.ndarray) -> np.ndarray:\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\"); s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]; rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]; rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def get_largest_poly_from_mask(binary_mask_img: np.ndarray) -> np.ndarray | None:\n",
    "    contours, _ = cv2.findContours(binary_mask_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours: return None\n",
    "    largest_contour = max(contours, key=cv2.contourArea); peri = cv2.arcLength(largest_contour, True)\n",
    "    approx_poly = cv2.approxPolyDP(largest_contour, 0.02 * peri, True)\n",
    "    if len(approx_poly) == 4: return np.squeeze(approx_poly)\n",
    "    else:\n",
    "        rect = cv2.minAreaRect(largest_contour)\n",
    "        box_points = cv2.boxPoints(rect)\n",
    "        return np.int0(box_points)\n",
    "\n",
    "def get_max_dimensions(point_array: np.ndarray) -> tuple[int, int]:\n",
    "    if point_array is None or len(point_array) != 4: return 0, 0\n",
    "    rect_ordered = order_points(point_array.astype(np.float32)); (tl, tr, br, bl) = rect_ordered\n",
    "    width_a = np.sqrt(((br[0] - bl[0])**2) + ((br[1] - bl[1])**2))\n",
    "    width_b = np.sqrt(((tr[0] - tl[0])**2) + ((tr[1] - tl[1])**2))\n",
    "    max_width = max(int(width_a), int(width_b))\n",
    "    height_a = np.sqrt(((tr[0] - br[0])**2) + ((tr[1] - br[1])**2))\n",
    "    height_b = np.sqrt(((tl[0] - bl[0])**2) + ((tl[1] - bl[1])**2))\n",
    "    max_height = max(int(height_a), int(height_b))\n",
    "    return max_width, max_height\n",
    "\n",
    "def get_perspective_transform_matrix(point_array: np.ndarray, target_width: int, target_height: int) -> np.ndarray | None:\n",
    "    if point_array is None or len(point_array) != 4 or target_width <= 0 or target_height <= 0: return None\n",
    "    src_pts_ordered = order_points(point_array.astype(np.float32))\n",
    "    dst_pts_ordered = np.float32([[0,0],[target_width-1,0],[target_width-1,target_height-1],[0,target_height-1]])\n",
    "    try: return cv2.getPerspectiveTransform(src_pts_ordered, dst_pts_ordered)\n",
    "    except cv2.error: return None\n",
    "\n",
    "def warp_image_from_mask(image_bgr: np.ndarray, binary_mask_img: np.ndarray) -> np.ndarray:\n",
    "    if image_bgr is None or image_bgr.size==0 or binary_mask_img is None or binary_mask_img.size==0: return image_bgr\n",
    "    poly_coords_from_mask = get_largest_poly_from_mask(binary_mask_img)\n",
    "    if poly_coords_from_mask is None or len(poly_coords_from_mask) != 4: return image_bgr\n",
    "    max_w_target, max_h_target = get_max_dimensions(poly_coords_from_mask)\n",
    "    if max_w_target <= 10 or max_h_target <= 10: return image_bgr\n",
    "    transform_matrix_calc = get_perspective_transform_matrix(poly_coords_from_mask, max_w_target, max_h_target)\n",
    "    if transform_matrix_calc is None: return image_bgr\n",
    "    try:\n",
    "        warped_image_result = cv2.warpPerspective(image_bgr, transform_matrix_calc, (max_w_target, max_h_target), flags=cv2.INTER_LANCZOS4)\n",
    "        return warped_image_result if warped_image_result is not None and warped_image_result.size > 0 else image_bgr\n",
    "    except Exception: return image_bgr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#                      *** Xoay, Chỉnh nghiêng trang ***\n",
    "# ==============================================================================\n",
    "def rotate_image_safe(image: np.ndarray, angle: float,\n",
    "    border_val: tuple[int, int, int] | int | None = None,\n",
    "    border_mode: int = cv2.BORDER_REPLICATE\n",
    ") -> np.ndarray:\n",
    "    if image is None or image.size == 0 or abs(angle) < 0.01:\n",
    "        return image\n",
    "    try:\n",
    "        h, w = image.shape[:2]; center = (w // 2, h // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        if border_val is None: border_val = (255,255,255) if image.ndim==3 else 255\n",
    "        rotated_image = cv2.warpAffine(image,rotation_matrix,(w,h),flags=cv2.INTER_LANCZOS4,borderMode=border_mode,borderValue=border_val)\n",
    "        return rotated_image if rotated_image is not None and rotated_image.size > 0 else image\n",
    "    except Exception as e_rotate:\n",
    "        print(f\"Cảnh báo: Lỗi trong quá trình xoay ảnh: {e_rotate}\")\n",
    "        return image\n",
    "\n",
    "def deskew_page_basic(image_bgr: np.ndarray, angle_thresh_deg: float = 1.0,\n",
    "    bg_color: tuple[int, int, int] = (255, 255, 255)\n",
    ") -> np.ndarray:\n",
    "    if image_bgr is None or image_bgr.size == 0: return image_bgr\n",
    "    original_image_copy = image_bgr.copy(); h_orig, w_orig = image_bgr.shape[:2]\n",
    "    try:\n",
    "        gray_img = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        try: thresh_inv_img = cv2.adaptiveThreshold(gray_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,21,10)\n",
    "        except cv2.error: _, thresh_inv_img = cv2.threshold(gray_img,0,255,cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)\n",
    "        kernel_width = max(15,int(w_orig*0.04)); kernel_height = max(3,int(h_orig*0.005))\n",
    "        morph_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_width,kernel_height))\n",
    "        dilated_img = cv2.dilate(thresh_inv_img,morph_kernel,iterations=2)\n",
    "        edges_img = cv2.Canny(dilated_img,50,150,apertureSize=3)\n",
    "        if cv2.countNonZero(edges_img)==0: return original_image_copy\n",
    "        hough_line_thresh=max(50,int(w_orig*0.1)); min_line_length_hough=max(40,int(w_orig*0.08)); max_line_gap_hough=max(10,int(w_orig*0.02))\n",
    "        lines_detected = cv2.HoughLinesP(edges_img,1,np.pi/180,hough_line_thresh,minLineLength=min_line_length_hough,maxLineGap=max_line_gap_hough)\n",
    "        if lines_detected is None or len(lines_detected)==0: return original_image_copy\n",
    "        detected_angles_deg = [math.degrees(math.atan2(line[0][3]-line[0][1],line[0][2]-line[0][0]))\n",
    "                               for line in lines_detected\n",
    "                               if line[0][2]!=line[0][0] and abs(math.degrees(math.atan2(line[0][3]-line[0][1],line[0][2]-line[0][0])))<30.0]\n",
    "        if not detected_angles_deg: return original_image_copy\n",
    "        median_detected_angle = float(np.median(detected_angles_deg))\n",
    "        if not np.isfinite(median_detected_angle): return original_image_copy\n",
    "        correction_angle_val = -median_detected_angle\n",
    "        if abs(correction_angle_val) >= angle_thresh_deg:\n",
    "            deskewed_img_result = rotate_image_safe(original_image_copy, correction_angle_val, border_val=bg_color)\n",
    "            return deskewed_img_result\n",
    "        return original_image_copy\n",
    "    except Exception as e_deskew_page:\n",
    "        print(f\"Cảnh báo: Lỗi trong quá trình chỉnh nghiêng trang: {e_deskew_page}\")\n",
    "        return original_image_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0cbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phần này chỉnh nghiêng bảng tuy nhiên chưa xử lý chưa xử lý perspective\n",
    "def deskew_table_precisely_v2(image_crop_bgr: np.ndarray, **dk_params) -> tuple[np.ndarray, float]:\n",
    "    if image_crop_bgr is None or image_crop_bgr.size==0: return image_crop_bgr,0.0\n",
    "    original_crop_copy = image_crop_bgr.copy(); h_crop,w_crop = original_crop_copy.shape[:2]\n",
    "    if h_crop<10 or w_crop<10: return original_crop_copy,0.0\n",
    "    applied_correction_angle=0.0; params=dk_params\n",
    "    try:\n",
    "        gray_crop = cv2.cvtColor(original_crop_copy,cv2.COLOR_BGR2GRAY)\n",
    "        try: bin_inv_crop = cv2.adaptiveThreshold(~gray_crop,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,15,-2)\n",
    "        except cv2.error: _,bin_inv_crop = cv2.threshold(~gray_crop,0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "        morph_kernel_w_factor = max(3,int(w_crop*params.get('morph_kernel_width_factor',0.15)))\n",
    "        h_line_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(morph_kernel_w_factor,1))\n",
    "        h_lines_mask = cv2.morphologyEx(bin_inv_crop,cv2.MORPH_OPEN,h_line_kernel,iterations=params.get('morph_iterations',1))\n",
    "        if cv2.countNonZero(h_lines_mask)<(w_crop*0.05): return original_crop_copy,0.0\n",
    "        edges_from_h_mask = cv2.Canny(h_lines_mask,params.get('canny_low_thresh',50),params.get('canny_high_thresh',150),apertureSize=3)\n",
    "        if cv2.countNonZero(edges_from_h_mask)==0: return original_crop_copy,0.0\n",
    "        table_lines = cv2.HoughLinesP(edges_from_h_mask,1,np.pi/180,\n",
    "            threshold=params.get('hough_threshold',25),\n",
    "            minLineLength=max(15,int(w_crop*params.get('hough_min_line_length_factor',0.2))),\n",
    "            maxLineGap=max(5,int(w_crop*params.get('hough_max_line_gap_factor',0.05))) )\n",
    "        if table_lines is None or len(table_lines)==0: return original_crop_copy,0.0\n",
    "        angle_filter_degrees_param = params.get('angle_filter_degrees',25.0)\n",
    "        h_detected_angles = [math.degrees(math.atan2(l_seg[0][3]-l_seg[0][1],l_seg[0][2]-l_seg[0][0]))\n",
    "                             for l_seg in table_lines\n",
    "                             if l_seg[0][2]!=l_seg[0][0] and abs(math.degrees(math.atan2(l_seg[0][3]-l_seg[0][1],l_seg[0][2]-l_seg[0][0])))<=angle_filter_degrees_param]\n",
    "        if not h_detected_angles: return original_crop_copy,0.0\n",
    "        median_horizontal_angle = float(np.median(h_detected_angles))\n",
    "        if not np.isfinite(median_horizontal_angle): return original_crop_copy,0.0\n",
    "        h_correction_angle = -median_horizontal_angle\n",
    "        if abs(h_correction_angle)>params.get('rotation_threshold_degrees',0.2):\n",
    "            rotated_table_crop = rotate_image_safe(original_crop_copy,h_correction_angle)\n",
    "            applied_correction_angle = h_correction_angle\n",
    "            return rotated_table_crop, applied_correction_angle\n",
    "        return original_crop_copy,0.0\n",
    "    except Exception as e_deskew_table:\n",
    "        print(f\"Cảnh báo: Lỗi trong quá trình chỉnh nghiêng bảng chính xác: {e_deskew_table}\")\n",
    "        return original_crop_copy,0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "#                       *** XỬ LÝ BẢNG ***\n",
    "# ==============================================================================\n",
    "def calculate_iou_xywh(box1_xywh:tuple[int,int,int,int],box2_xywh:tuple[int,int,int,int])->float:\n",
    "    x1_i,y1_i,w1_i,h1_i=box1_xywh; x2_i,y2_i,w2_i,h2_i=box2_xywh\n",
    "    b1_x_min,b1_y_min,b1_x_max,b1_y_max = x1_i,y1_i,x1_i+w1_i,y1_i+h1_i\n",
    "    b2_x_min,b2_y_min,b2_x_max,b2_y_max = x2_i,y2_i,x2_i+w2_i,y2_i+h2_i\n",
    "    inter_x_min=max(b1_x_min,b2_x_min); inter_y_min=max(b1_y_min,b2_y_min)\n",
    "    inter_x_max=min(b1_x_max,b2_x_max); inter_y_max=min(b1_y_max,b2_y_max)\n",
    "    if inter_x_max<inter_x_min or inter_y_max<inter_y_min: return 0.0\n",
    "    intersection_area=(inter_x_max-inter_x_min)*(inter_y_max-inter_y_min)\n",
    "    b1_area=w1_i*h1_i; b2_area=w2_i*h2_i\n",
    "    union_area=float(b1_area+b2_area-intersection_area)\n",
    "    if union_area <= 0: return 0.0 if intersection_area == 0 else 1.0\n",
    "    return intersection_area/union_area\n",
    "\n",
    "def detect_tables_cv_tt_combined(\n",
    "    page_image_path:str|Path, output_dir_prefix:str,\n",
    "    cv_detect_params:dict, table_deskew_params:dict,\n",
    "    iou_match_threshold:float=0.4, tt_page_confidence_threshold:float=0.6,\n",
    "    # Truyền các model đã load vào\n",
    "    tt_detection_model: 'TableTransformerForObjectDetection',\n",
    "    tt_detection_processor: 'AutoImageProcessor',\n",
    "    tt_structure_model: 'TableTransformerForObjectDetection',\n",
    "    # tt_structure_processor: 'AutoImageProcessor', # Có thể dùng chung processor\n",
    "    easyocr_reader: 'easyocr.Reader'\n",
    ") -> list[str]:\n",
    "    global TT_DETECTION_MODEL, TT_DETECTION_PROCESSOR, TT_STRUCTURE_MODEL, EASYOCR_READER, DEVICE\n",
    "\n",
    "    if not TT_DETECTION_MODEL or not TT_DETECTION_PROCESSOR or \\\n",
    "       not TT_STRUCTURE_MODEL or not EASYOCR_READER:\n",
    "        print(\"Lỗi: Một hoặc nhiều model cần thiết (TT Detection, TT Structure, EasyOCR) chưa được tải.\")\n",
    "        return []\n",
    "\n",
    "    saved_crop_paths_list:list[str]=[]; page_file_path=Path(page_image_path); page_base_name=page_file_path.name\n",
    "    img_page_bgr_original_data=cv2.imread(str(page_file_path))\n",
    "    if img_page_bgr_original_data is None: print(f\"Lỗi: Không thể đọc ảnh trang: {page_file_path}\"); return []\n",
    "\n",
    "    page_height,page_width = img_page_bgr_original_data.shape[:2]\n",
    "    if page_height<=10 or page_width<=10: print(f\"Lỗi: Kích thước ảnh trang quá nhỏ: {page_file_path}\"); return []\n",
    "    # print(f\"\\n--- Đang xử lý trang: {page_base_name} ---\")\n",
    "\n",
    "    cv_candidate_bboxes_xywh_list:list[tuple[int,int,int,int]]=[]\n",
    "    try:\n",
    "        dt_params_cv=cv_detect_params; gray_page_img=cv2.cvtColor(img_page_bgr_original_data,cv2.COLOR_BGR2GRAY)\n",
    "        try:thresh_inv_page_img=cv2.adaptiveThreshold(~gray_page_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,15,-2)\n",
    "        except:_,thresh_inv_page_img=cv2.threshold(~gray_page_img,0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "        kernel_h_width=max(20,int(page_width*dt_params_cv.get('min_line_ratio',0.02)))\n",
    "        kernel_v_height=max(20,int(page_height*dt_params_cv.get('min_line_ratio',0.02)))\n",
    "        kernel_h_lines=cv2.getStructuringElement(cv2.MORPH_RECT,(kernel_h_width,1))\n",
    "        kernel_v_lines=cv2.getStructuringElement(cv2.MORPH_RECT,(1,kernel_v_height))\n",
    "        opened_h_lines_mask=cv2.morphologyEx(thresh_inv_page_img,cv2.MORPH_OPEN,kernel_h_lines)\n",
    "        opened_v_lines_mask=cv2.morphologyEx(thresh_inv_page_img,cv2.MORPH_OPEN,kernel_v_lines)\n",
    "        combined_lines_mask=cv2.addWeighted(opened_h_lines_mask,0.5,opened_v_lines_mask,0.5,0.0)\n",
    "        dilate_iterations_cv=dt_params_cv.get('dilate_iter',2)\n",
    "        if dilate_iterations_cv > 0:\n",
    "            final_cv_mask = cv2.dilate(combined_lines_mask,cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)),iterations=dilate_iterations_cv)\n",
    "        else:\n",
    "            final_cv_mask = combined_lines_mask\n",
    "        if final_cv_mask is None or cv2.countNonZero(final_cv_mask)==0: raise ValueError(\"Mặt nạ OpenCV rỗng.\")\n",
    "        cv_contours_found,_=cv2.findContours(final_cv_mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if not cv_contours_found: raise ValueError(\"Không tìm thấy đường viền nào bởi OpenCV.\")\n",
    "        min_area_pixels_cv=dt_params_cv.get('min_area_ratio',0.008)*page_width*page_height\n",
    "        min_dimension_pixels_cv=dt_params_cv.get('min_dim_px',25)\n",
    "        candidate_contours_data_list = []\n",
    "        for c_item in cv_contours_found:\n",
    "            x_c, y_c, w_c, h_c = cv2.boundingRect(c_item)\n",
    "            area_c = cv2.contourArea(c_item)\n",
    "            if area_c > min_area_pixels_cv and w_c > min_dimension_pixels_cv and h_c > min_dimension_pixels_cv:\n",
    "                candidate_contours_data_list.append({'bbox_xywh': (x_c, y_c, w_c, h_c), 'area': area_c})\n",
    "        if not candidate_contours_data_list: raise ValueError(\"Không có đường viền OpenCV nào vượt qua bộ lọc kích thước/diện tích.\")\n",
    "        candidate_contours_data_list.sort(key=lambda item:item['area'],reverse=True)\n",
    "        selected_indices_cv=set(); final_cv_candidates_list=[]\n",
    "        overlap_threshold_cv=dt_params_cv.get('overlap_threshold_ratio',0.7)\n",
    "        for i_idx in range(len(candidate_contours_data_list)):\n",
    "            if i_idx in selected_indices_cv: continue\n",
    "            current_contour_data=candidate_contours_data_list[i_idx]\n",
    "            final_cv_candidates_list.append(current_contour_data['bbox_xywh'])\n",
    "            for j_idx in range(i_idx + 1, len(candidate_contours_data_list)):\n",
    "                if j_idx in selected_indices_cv: continue\n",
    "                other_contour_data=candidate_contours_data_list[j_idx]\n",
    "                xA_overlap=max(current_contour_data['bbox_xywh'][0],other_contour_data['bbox_xywh'][0])\n",
    "                yA_overlap=max(current_contour_data['bbox_xywh'][1],other_contour_data['bbox_xywh'][1])\n",
    "                xB_overlap=min(current_contour_data['bbox_xywh'][0]+current_contour_data['bbox_xywh'][2],other_contour_data['bbox_xywh'][0]+other_contour_data['bbox_xywh'][2])\n",
    "                yB_overlap=min(current_contour_data['bbox_xywh'][1]+current_contour_data['bbox_xywh'][3],other_contour_data['bbox_xywh'][1]+other_contour_data['bbox_xywh'][3])\n",
    "                intersection_area_val=max(0,xB_overlap-xA_overlap)*max(0,yB_overlap-yA_overlap)\n",
    "                if intersection_area_val > 0 and (intersection_area_val/min(current_contour_data['area'],other_contour_data['area'])) > overlap_threshold_cv:\n",
    "                    selected_indices_cv.add(j_idx)\n",
    "        cv_candidate_bboxes_xywh_list = final_cv_candidates_list\n",
    "        print(f\"  > Phát hiện OpenCV: Tìm thấy {len(cv_candidate_bboxes_xywh_list)} vùng ứng viên sau khi lọc.\")\n",
    "    except Exception as e_cv_detect: print(f\"  > Cảnh báo: Lỗi giai đoạn phát hiện OpenCV: {e_cv_detect}\"); cv_candidate_bboxes_xywh_list=[]\n",
    "\n",
    "    tt_detected_bboxes_on_page_xywh_list:list[tuple[int,int,int,int]]=[]\n",
    "    if TT_DETECTION_MODEL and TT_DETECTION_PROCESSOR:\n",
    "        try:\n",
    "            pil_page_img = Image.fromarray(cv2.cvtColor(img_page_bgr_original_data,cv2.COLOR_BGR2RGB))\n",
    "            tt_inputs = TT_DETECTION_PROCESSOR(images=pil_page_img,return_tensors=\"pt\")\n",
    "            tt_model_device = next(TT_DETECTION_MODEL.parameters()).device\n",
    "            tt_inputs = {k_item:v_item.to(tt_model_device) for k_item,v_item in tt_inputs.items()}\n",
    "            with torch.no_grad(): tt_outputs = TT_DETECTION_MODEL(**tt_inputs)\n",
    "            tt_target_sizes=torch.tensor([pil_page_img.size[::-1]],device=tt_model_device)\n",
    "            tt_results_list = TT_DETECTION_PROCESSOR.post_process_object_detection(\n",
    "                tt_outputs, threshold=tt_page_confidence_threshold, target_sizes=tt_target_sizes\n",
    "            )[0]\n",
    "            min_dim_pixels_tt = cv_detect_params.get('min_dim_px',25)\n",
    "            for score_val,label_val,box_xyxy_val in zip(tt_results_list[\"scores\"],tt_results_list[\"labels\"],tt_results_list[\"boxes\"]):\n",
    "                if \"table\" in TT_DETECTION_MODEL.config.id2label[label_val.item()].lower():\n",
    "                    xmin_val,ymin_val,xmax_val,ymax_val=[int(round(c_coord.item())) for c_coord in box_xyxy_val]\n",
    "                    w_val,h_val=xmax_val-xmin_val,ymax_val-ymin_val\n",
    "                    if w_val > min_dim_pixels_tt and h_val > min_dim_pixels_tt:\n",
    "                        tt_detected_bboxes_on_page_xywh_list.append((xmin_val,ymin_val,w_val,h_val))\n",
    "            print(f\"  > Table Transformer (Cấp trang): Tìm thấy {len(tt_detected_bboxes_on_page_xywh_list)} \"\n",
    "                  f\"vùng (độ tin cậy > {tt_page_confidence_threshold}).\")\n",
    "        except Exception as e_tt_page_detect: print(f\"  > Cảnh báo: Lỗi phát hiện cấp trang Table Transformer: {e_tt_page_detect}\"); tt_detected_bboxes_on_page_xywh_list=[]\n",
    "    else:\n",
    "        print(\"  > Mô hình Table Transformer Detection không khả dụng. Bỏ qua phát hiện cấp trang TT.\")\n",
    "\n",
    "    final_confirmed_pairs_data_list = []\n",
    "    if cv_candidate_bboxes_xywh_list and tt_detected_bboxes_on_page_xywh_list:\n",
    "        print(f\"  > So sánh: Đang so sánh {len(cv_candidate_bboxes_xywh_list)} bboxes CV với \"\n",
    "              f\"{len(tt_detected_bboxes_on_page_xywh_list)} bboxes TT...\")\n",
    "        sorted_cv_bboxes_list = sorted(cv_candidate_bboxes_xywh_list,key=lambda b_item:(b_item[1],b_item[0]))\n",
    "        for cv_bbox_item in sorted_cv_bboxes_list:\n",
    "            best_iou_for_this_cv_bbox = 0.0; best_tt_match_for_this_cv_bbox = None\n",
    "            for tt_bbox_item in tt_detected_bboxes_on_page_xywh_list:\n",
    "                iou_val = calculate_iou_xywh(cv_bbox_item, tt_bbox_item)\n",
    "                if iou_val > best_iou_for_this_cv_bbox:\n",
    "                    best_iou_for_this_cv_bbox = iou_val\n",
    "                    best_tt_match_for_this_cv_bbox = tt_bbox_item\n",
    "            if best_iou_for_this_cv_bbox > iou_match_threshold and best_tt_match_for_this_cv_bbox is not None:\n",
    "                final_confirmed_pairs_data_list.append({\n",
    "                    \"cv_bbox\": cv_bbox_item, \"tt_bbox\": best_tt_match_for_this_cv_bbox, \"iou\": best_iou_for_this_cv_bbox\n",
    "                })\n",
    "        print(f\"    - Tìm thấy {len(final_confirmed_pairs_data_list)} cặp CV-TT có IoU > {iou_match_threshold}.\")\n",
    "\n",
    "    if not final_confirmed_pairs_data_list:\n",
    "        print(f\"  > So sánh: Không có bảng nào vượt qua ngưỡng khớp IoU {iou_match_threshold}. Không có crop nào để xử lý.\")\n",
    "        return []\n",
    "    print(f\"  > So sánh: {len(final_confirmed_pairs_data_list)} bboxes CV được xác nhận bởi TT. Đang tiến hành xử lý...\")\n",
    "\n",
    "    processed_table_count = 0\n",
    "    for pair_index, pair_item_data in enumerate(final_confirmed_pairs_data_list):\n",
    "        cv_bbox_to_process_item = pair_item_data[\"cv_bbox\"]\n",
    "        matched_tt_bbox_absolute = pair_item_data[\"tt_bbox\"]\n",
    "        iou_score_val = pair_item_data[\"iou\"]\n",
    "\n",
    "        if SHOW_PROCESSING_IMAGES:\n",
    "            display_image_with_bboxes(\n",
    "                title=f\"Trang {page_base_name} - Khớp {pair_index+1} (IoU {iou_score_val:.2f})\",\n",
    "                image_np=img_page_bgr_original_data,\n",
    "                cv_bbox_abs=cv_bbox_to_process_item, tt_bbox_abs=matched_tt_bbox_absolute\n",
    "            )\n",
    "        x_cv_coord, y_cv_coord, w_cv_dim, h_cv_dim = cv_bbox_to_process_item\n",
    "        padding_val = cv_detect_params.get('padding',5)\n",
    "        y1_crop_coord = max(0, y_cv_coord - padding_val); y2_crop_coord = min(page_height, y_cv_coord + h_cv_dim + padding_val)\n",
    "        x1_crop_coord = max(0, x_cv_coord - padding_val); x2_crop_coord = min(page_width, x_cv_coord + w_cv_dim + padding_val)\n",
    "\n",
    "        if (x2_crop_coord - x1_crop_coord) <= 10 or (y2_crop_coord - y1_crop_coord) <= 10:\n",
    "            print(f\"    - Xử lý: CV crop {pair_index+1} quá nhỏ. Bỏ qua.\"); continue\n",
    "        cv_crop_bgr_padded_img = img_page_bgr_original_data[y1_crop_coord:y2_crop_coord, x1_crop_coord:x2_crop_coord].copy()\n",
    "        if cv_crop_bgr_padded_img is None or cv_crop_bgr_padded_img.size == 0:\n",
    "            print(f\"    - Xử lý: CV crop rỗng {pair_index+1}. Bỏ qua.\"); continue\n",
    "\n",
    "        deskewed_table_crop_img = cv_crop_bgr_padded_img.copy()\n",
    "        try:\n",
    "            deskewed_output_img, applied_angle_val = deskew_table_precisely_v2(cv_crop_bgr_padded_img, **table_deskew_params)\n",
    "            if deskewed_output_img is not None and deskewed_output_img.size > 0:\n",
    "                deskewed_table_crop_img = deskewed_output_img\n",
    "                if abs(applied_angle_val) > 0.01: print(f\"      - Đã áp dụng Chỉnh nghiêng chính xác: {applied_angle_val:.2f}°\")\n",
    "        except Exception as e_deskew_crop: print(f\"    - Cảnh báo: Lỗi chỉnh nghiêng bảng chính xác cho crop {pair_index+1}: {e_deskew_crop}\")\n",
    "\n",
    "        final_processed_crop_for_saving_img = deskewed_table_crop_img.copy()\n",
    "        try:\n",
    "            if deskewed_table_crop_img is not None and deskewed_table_crop_img.size > 0:\n",
    "                gray_for_warp_mask_img = cv2.cvtColor(deskewed_table_crop_img, cv2.COLOR_BGR2GRAY)\n",
    "                _, bin_for_warp_mask_img = cv2.threshold(gray_for_warp_mask_img, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "                warped_output_img = warp_image_from_mask(deskewed_table_crop_img, bin_for_warp_mask_img)\n",
    "                if warped_output_img is not None and warped_output_img.size > 0 and \\\n",
    "                   warped_output_img.shape[0] > 10 and warped_output_img.shape[1] > 10:\n",
    "                    final_processed_crop_for_saving_img = warped_output_img\n",
    "        except Exception as e_warp_crop: print(f\"    - Cảnh báo: Lỗi perspective warp cho crop {pair_index+1}: {e_warp_crop}\")\n",
    "\n",
    "        if final_processed_crop_for_saving_img is not None and final_processed_crop_for_saving_img.size > 0:\n",
    "            processed_table_count += 1\n",
    "            if SHOW_PROCESSING_IMAGES:\n",
    "                display_processed_crop(\n",
    "                    title=f\"Trang {page_base_name} - CV-Crop đã xử lý {processed_table_count} (IoU {iou_score_val:.2f})\",\n",
    "                    processed_crop_np=final_processed_crop_for_saving_img\n",
    "                )\n",
    "            \n",
    "            # --- Chuyển sang PIL Image để xử lý cấu trúc ---\n",
    "            # Ảnh đầu vào cho structure model là final_processed_crop_for_saving_img\n",
    "            h_orig_crop, w_orig_crop = final_processed_crop_for_saving_img.shape[:2]\n",
    "            \n",
    "            # Resize nếu quá lớn cho model structure (thường có giới hạn kích thước đầu vào)\n",
    "            # MaxResize class và structure_transform vẫn giữ nguyên như code gốc\n",
    "            class MaxResize(object):\n",
    "                def __init__(self, max_size=1000): # Giữ nguyên 1000 hoặc điều chỉnh\n",
    "                    self.max_size = max_size\n",
    "                def __call__(self, image_pil):\n",
    "                    width, height = image_pil.size\n",
    "                    current_max_size = max(width, height)\n",
    "                    if current_max_size > self.max_size:\n",
    "                        scale = self.max_size / current_max_size\n",
    "                        return image_pil.resize((int(round(scale * width)), int(round(scale * height))))\n",
    "                    return image_pil\n",
    "\n",
    "            structure_transform = transforms.Compose([\n",
    "                MaxResize(1000), # Áp dụng MaxResize\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            \n",
    "            pil_crop_image_for_structure = Image.fromarray(cv2.cvtColor(final_processed_crop_for_saving_img, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # Lưu kích thước gốc của ảnh PIL *trước khi* transform để rescale bbox sau này\n",
    "            pil_crop_image_for_structure_resized = MaxResize(1000)(pil_crop_image_for_structure.copy()) # Get the size after potential resize\n",
    "            original_pil_size_for_rescale = pil_crop_image_for_structure_resized.size\n",
    "\n",
    "\n",
    "            pixel_values = structure_transform(pil_crop_image_for_structure).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs_structure = TT_STRUCTURE_MODEL(pixel_values)\n",
    "\n",
    "            def box_cxcywh_to_xyxy(x):\n",
    "                x_c, y_c, w, h = x.unbind(-1)\n",
    "                b = [(x_c - 0.5 * w), (y_c - 0.5 * h), (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "                return torch.stack(b, dim=1)\n",
    "\n",
    "            def rescale_bboxes(out_bbox, size): # size là (width, height) của ảnh đầu vào cho model\n",
    "                img_w, img_h = size\n",
    "                b = box_cxcywh_to_xyxy(out_bbox)\n",
    "                b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32, device=out_bbox.device) # device match\n",
    "                return b\n",
    "\n",
    "            def outputs_to_objects(outputs, img_size, id2label_map): # img_size là kích thước ảnh mà model thấy\n",
    "                m = outputs.logits.softmax(-1).max(-1)\n",
    "                pred_labels = list(m.indices.detach().cpu().numpy())[0]\n",
    "                pred_scores = list(m.values.detach().cpu().numpy())[0]\n",
    "                pred_bboxes_normalized = outputs['pred_boxes'].detach().cpu()[0] # Bboxes này là normalized [0,1] cxcywh\n",
    "                \n",
    "                # Rescale bboxes về kích thước ảnh đầu vào của model structure (sau MaxResize)\n",
    "                pred_bboxes_rescaled_xyxy = [elem.tolist() for elem in rescale_bboxes(pred_bboxes_normalized, img_size)]\n",
    "\n",
    "                objects = []\n",
    "                for label, score, bbox_xyxy in zip(pred_labels, pred_scores, pred_bboxes_rescaled_xyxy):\n",
    "                    class_label = id2label_map[int(label)]\n",
    "                    if class_label != \"no object\": # và có thể thêm score threshold\n",
    "                        objects.append({'label': class_label, 'score': float(score), \n",
    "                                        'bbox_xyxy_rescaled': bbox_xyxy}) # Lưu bbox đã rescale\n",
    "                return objects\n",
    "\n",
    "            structure_id2label = TT_STRUCTURE_MODEL.config.id2label\n",
    "            structure_id2label[len(structure_id2label)] = \"no object\" # Thêm nhãn \"no object\"\n",
    "            \n",
    "            # Sử dụng original_pil_size_for_rescale (kích thước ảnh sau MaxResize)\n",
    "            cells_detected_structure = outputs_to_objects(outputs_structure, original_pil_size_for_rescale, structure_id2label)\n",
    "\n",
    "\n",
    "            def get_cell_coordinates_by_row(table_data_structure, img_pil_for_ocr: Image.Image):\n",
    "                # table_data_structure chứa các 'bbox_xyxy_rescaled'\n",
    "                # img_pil_for_ocr là ảnh PIL mà từ đó các cell sẽ được crop (ảnh gốc của crop table, trước khi ToTensor/Normalize)\n",
    "                \n",
    "                rows = [entry for entry in table_data_structure if entry['label'] == 'table row']\n",
    "                columns = [entry for entry in table_data_structure if entry['label'] == 'table column']\n",
    "                \n",
    "                # Sắp xếp rows theo tọa độ y_min, columns theo x_min\n",
    "                rows.sort(key=lambda x: x['bbox_xyxy_rescaled'][1])\n",
    "                columns.sort(key=lambda x: x['bbox_xyxy_rescaled'][0])\n",
    "\n",
    "                # Bỏ các cột/hàng chồng lấn quá nhiều hoặc không hợp lệ (tùy chọn, có thể phức tạp)\n",
    "                # Ví dụ: nếu 2 cột có x_min quá gần nhau, có thể là lỗi phát hiện\n",
    "\n",
    "                cell_coordinates_extracted = []\n",
    "                img_w_ocr, img_h_ocr = img_pil_for_ocr.size # Kích thước của ảnh gốc dùng để crop OCR\n",
    "\n",
    "                # Tính scale factor nếu kích thước ảnh dùng cho model structure khác với ảnh OCR\n",
    "                # original_pil_size_for_rescale là (width, height) của ảnh sau MaxResize (mà model structure thấy)\n",
    "                scale_x = img_w_ocr / original_pil_size_for_rescale[0]\n",
    "                scale_y = img_h_ocr / original_pil_size_for_rescale[1]\n",
    "\n",
    "\n",
    "                for row_info in rows:\n",
    "                    row_cells_info = []\n",
    "                    y_min_row, y_max_row = row_info['bbox_xyxy_rescaled'][1], row_info['bbox_xyxy_rescaled'][3]\n",
    "\n",
    "                    for col_info in columns:\n",
    "                        x_min_col, x_max_col = col_info['bbox_xyxy_rescaled'][0], col_info['bbox_xyxy_rescaled'][2]\n",
    "                        \n",
    "                        # Tạo bounding box cho cell từ giao của row và column\n",
    "                        # Đây là tọa độ trên ảnh đã qua MaxResize\n",
    "                        cell_bbox_rescaled_xyxy = [x_min_col, y_min_row, x_max_col, y_max_row]\n",
    "\n",
    "                        # Chuyển đổi bbox này về tọa độ của ảnh gốc (img_pil_for_ocr) để crop\n",
    "                        # bbox for cropping on the original image\n",
    "                        # Tọa độ cell trên ảnh gốc (dùng để crop cho OCR)\n",
    "                        final_crop_coords_on_original_img = [\n",
    "                            int(cell_bbox_rescaled_xyxy[0] * scale_x),\n",
    "                            int(cell_bbox_rescaled_xyxy[1] * scale_y),\n",
    "                            int(cell_bbox_rescaled_xyxy[2] * scale_x),\n",
    "                            int(cell_bbox_rescaled_xyxy[3] * scale_y)\n",
    "                        ]\n",
    "                        # Đảm bảo tọa độ nằm trong ảnh\n",
    "                        final_crop_coords_on_original_img[0] = max(0, final_crop_coords_on_original_img[0])\n",
    "                        final_crop_coords_on_original_img[1] = max(0, final_crop_coords_on_original_img[1])\n",
    "                        final_crop_coords_on_original_img[2] = min(img_w_ocr, final_crop_coords_on_original_img[2])\n",
    "                        final_crop_coords_on_original_img[3] = min(img_h_ocr, final_crop_coords_on_original_img[3])\n",
    "\n",
    "\n",
    "                        # Chỉ thêm cell nếu nó có kích thước hợp lệ\n",
    "                        if final_crop_coords_on_original_img[2] > final_crop_coords_on_original_img[0] and \\\n",
    "                           final_crop_coords_on_original_img[3] > final_crop_coords_on_original_img[1]:\n",
    "                            row_cells_info.append({\n",
    "                                'column_bbox_rescaled': col_info['bbox_xyxy_rescaled'], # Bbox cột trên ảnh rescaled\n",
    "                                'cell_bbox_for_ocr': final_crop_coords_on_original_img # Bbox cell trên ảnh gốc để OCR\n",
    "                            })\n",
    "                    \n",
    "                    # Sắp xếp các cell trong hàng theo tọa độ x_min của cột\n",
    "                    row_cells_info.sort(key=lambda x: x['column_bbox_rescaled'][0])\n",
    "                    if row_cells_info: # Chỉ thêm hàng nếu có cell\n",
    "                        cell_coordinates_extracted.append({\n",
    "                            'row_bbox_rescaled': row_info['bbox_xyxy_rescaled'], # Bbox hàng trên ảnh rescaled\n",
    "                            'cells': row_cells_info,\n",
    "                            'cell_count': len(row_cells_info)\n",
    "                        })\n",
    "                \n",
    "                # Sắp xếp các hàng theo tọa độ y_min của hàng\n",
    "                cell_coordinates_extracted.sort(key=lambda x: x['row_bbox_rescaled'][1])\n",
    "                return cell_coordinates_extracted\n",
    "\n",
    "            # Sử dụng pil_crop_image_for_structure (ảnh PIL gốc của crop, trước khi ToTensor/Normalize) để OCR\n",
    "            cell_coords_for_ocr = get_cell_coordinates_by_row(cells_detected_structure, pil_crop_image_for_structure)\n",
    "\n",
    "            def apply_ocr_to_cells(cell_coordinates_input, ocr_reader, image_to_crop_from: Image.Image):\n",
    "                ocr_data = dict()\n",
    "                max_cols = 0\n",
    "                if not ocr_reader:\n",
    "                    print(\"Lỗi: EasyOCR Reader không khả dụng cho việc OCR cell.\")\n",
    "                    return {}, 0\n",
    "                \n",
    "                for r_idx, row_data_item in enumerate(tqdm(cell_coordinates_input, desc=\"OCR Cells\")):\n",
    "                    current_row_texts = []\n",
    "                    for cell_item in row_data_item[\"cells\"]:\n",
    "                        # cell_item[\"cell_bbox_for_ocr\"] là tọa độ [x_min, y_min, x_max, y_max] trên image_to_crop_from\n",
    "                        cell_bbox = cell_item[\"cell_bbox_for_ocr\"]\n",
    "                        \n",
    "                        # Crop cell từ image_to_crop_from (ảnh PIL gốc của table crop)\n",
    "                        cropped_cell_pil = image_to_crop_from.crop(cell_bbox)\n",
    "                        cropped_cell_np = np.array(cropped_cell_pil) # Chuyển sang Numpy array cho EasyOCR\n",
    "\n",
    "                        ocr_results = ocr_reader.readtext(cropped_cell_np)\n",
    "                        if ocr_results:\n",
    "                            text = \" \".join([res_text for _, res_text, _ in ocr_results])\n",
    "                            current_row_texts.append(text)\n",
    "                        else:\n",
    "                            current_row_texts.append(\"\")\n",
    "                    \n",
    "                    if current_row_texts: # Chỉ thêm nếu hàng có text (hoặc ô trống)\n",
    "                        ocr_data[r_idx] = current_row_texts\n",
    "                        if len(current_row_texts) > max_cols:\n",
    "                            max_cols = len(current_row_texts)\n",
    "                \n",
    "                # Pad các hàng thiếu cột\n",
    "                for r_key in ocr_data:\n",
    "                    while len(ocr_data[r_key]) < max_cols:\n",
    "                        ocr_data[r_key].append(\"\")\n",
    "                return ocr_data, max_cols\n",
    "\n",
    "            # Truyền EASYOCR_READER và pil_crop_image_for_structure (ảnh PIL gốc của crop)\n",
    "            extracted_data_dict, num_cols = apply_ocr_to_cells(cell_coords_for_ocr, EASYOCR_READER, pil_crop_image_for_structure)\n",
    "\n",
    "            if extracted_data_dict:\n",
    "                print(f\"\\n--- Dữ liệu bảng {processed_table_count} trích xuất (số cột: {num_cols}) ---\")\n",
    "                df = pd.DataFrame.from_dict(extracted_data_dict, orient='index')\n",
    "                # Đặt tên cột nếu muốn: df.columns = [f\"Cột {j+1}\" for j in range(num_cols)]\n",
    "                print(df.to_string()) # In ra console\n",
    "\n",
    "                #---- Lưu CSV ---\n",
    "                try:\n",
    "                    root_tk = Tk()\n",
    "                    root_tk.withdraw()\n",
    "                    default_csv_name = f\"{Path(output_dir_prefix).name}_table_{processed_table_count:02d}_iou{iou_score_val:.2f}.csv\"\n",
    "                    csv_file_path = filedialog.asksaveasfilename(\n",
    "                        initialfile=default_csv_name,\n",
    "                        defaultextension=\".csv\",\n",
    "                        filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")],\n",
    "                        title=\"Chọn nơi lưu file CSV cho bảng\"\n",
    "                    )\n",
    "                    if csv_file_path:\n",
    "                        df.to_csv(csv_file_path, index=False, encoding='utf-8-sig') # encoding tốt cho tiếng Việt\n",
    "                        print(f\"    - Đã lưu dữ liệu bảng vào: {csv_file_path}\")\n",
    "                    else:\n",
    "                        print(\"    - Lưu CSV bị hủy.\")\n",
    "                    root_tk.destroy() # Quan trọng: đóng cửa sổ Tkinter ẩn\n",
    "                except Exception as e_csv:\n",
    "                    print(f\"    - LỖI khi lưu CSV: {e_csv}\")\n",
    "            else:\n",
    "                print(f\"    - Không có dữ liệu nào được trích xuất từ bảng {processed_table_count}.\")\n",
    "\n",
    "\n",
    "            # Lưu ảnh crop đã xử lý (ảnh bảng trực quan)\n",
    "            safe_prefix_filename = \"\".join(c if c.isalnum() or c in ('_', '-') else '_' for c in Path(output_dir_prefix).name)\n",
    "            output_table_filename = f\"{safe_prefix_filename}_table_CVmatchTT_{processed_table_count:02d}_iou{iou_score_val:.2f}.png\"\n",
    "            output_table_path = Path(Path(output_dir_prefix).parent) / output_table_filename\n",
    "\n",
    "            try:\n",
    "                if cv2.imwrite(str(output_table_path), final_processed_crop_for_saving_img):\n",
    "                    saved_crop_paths_list.append(str(output_table_path))\n",
    "                    print(f\"    - Đã lưu ảnh bảng đã xử lý vào: {output_table_path}\")\n",
    "                else:\n",
    "                    print(f\"    - LỖI: Không thể lưu ảnh bảng (cv2.imwrite trả về False): {output_table_path}\")\n",
    "            except Exception as e_save_table:\n",
    "                print(f\"    - LỖI: Ngoại lệ khi lưu ảnh bảng {output_table_path}: {e_save_table}\")\n",
    "        else:\n",
    "            print(f\"    - Xử lý: Crop cuối cùng cho cặp {pair_index+1} không hợp lệ hoặc rỗng. Không được lưu.\")\n",
    "    if SHOW_PROCESSING_IMAGES:\n",
    "        cv2.destroyAllWindows() # Đóng tất cả cửa sổ OpenCV khi xong một trang\n",
    "    return saved_crop_paths_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_for_tables_pipeline(\n",
    "    pdf_file_path_main:str|Path, base_output_dir_prefix:str, pdf_processing_dpi:int, enable_pdf_page_deskew:bool,\n",
    "    pdf_page_deskew_angle_thresh:float, cv_detection_config_main:dict, table_deskew_config_main:dict,\n",
    "    iou_matching_thresh_config:float, tt_page_confidence_thresh_config_val:float, temp_pdf_pages_dir_path:str|Path,\n",
    "    # Truyền các model đã load\n",
    "    tt_detection_model_loaded, tt_detection_processor_loaded,\n",
    "    tt_structure_model_loaded, easyocr_reader_loaded\n",
    "\n",
    ") -> tuple[dict[int,list[str]],int]:\n",
    "\n",
    "    all_page_processing_results:dict[int,list[str]]={}; total_tables_extracted_count=0\n",
    "    pdf_path_obj=Path(pdf_file_path_main)\n",
    "    temp_pages_dir_obj=Path(temp_pdf_pages_dir_path)\n",
    "\n",
    "    shutil.rmtree(temp_pages_dir_obj, ignore_errors=True)\n",
    "    os.makedirs(temp_pages_dir_obj, exist_ok=True)\n",
    "    output_main_dir=Path(base_output_dir_prefix).parent\n",
    "    if not output_main_dir.exists(): os.makedirs(output_main_dir, exist_ok=True)\n",
    "\n",
    "    pdf_page_pil_images_list:list[Image.Image]=[]\n",
    "    try:\n",
    "        # print(f\"  Đang chuyển đổi PDF '{pdf_path_obj.name}' (DPI:{pdf_processing_dpi})...\")\n",
    "        start_conversion_time=time.time(); cpu_cores_count=os.cpu_count()or 4; thread_count_val=max(1,cpu_cores_count//2)\n",
    "        # Kiểm tra poppler_path cho Windows nếu cần\n",
    "        poppler_path_env = os.getenv(\"POPPLER_PATH\") # Ví dụ: C:/path/to/poppler-xxx/bin\n",
    "        \n",
    "        pdf_page_pil_images_list = convert_from_path(\n",
    "            pdf_path_obj, dpi=pdf_processing_dpi, fmt='png',\n",
    "            thread_count=thread_count_val, use_pdftocairo=True,\n",
    "            poppler_path=poppler_path_env # Sẽ là None nếu không đặt, pdf2image tự tìm\n",
    "        )\n",
    "        conversion_duration_sec=time.time()-start_conversion_time\n",
    "        # print(f\"  Chuyển đổi PDF hoàn tất: {len(pdf_page_pil_images_list)} trang trong {conversion_duration_sec:.2f} giây.\")\n",
    "        if not pdf_page_pil_images_list: raise ValueError(\"Chuyển đổi PDF cho ra 0 hình ảnh.\")\n",
    "    except Exception as e_pdf_convert:\n",
    "        print(f\"LỖI NGHIÊM TRỌNG: Chuyển đổi PDF sang ảnh thất bại: {e_pdf_convert}\")\n",
    "        if \"poppler\" in str(e_pdf_convert).lower() and poppler_path_env is None:\n",
    "             print(\" gợi ý: Nếu trên Windows, hãy thử đặt biến môi trường POPPLER_PATH trỏ đến thư mục bin của Poppler.\")\n",
    "        shutil.rmtree(temp_pages_dir_obj, ignore_errors=True); return {}, 0\n",
    "\n",
    "    for current_page_idx, current_pil_image in enumerate(pdf_page_pil_images_list):\n",
    "        current_page_num = current_page_idx + 1\n",
    "        temp_page_image_file_path:Path|None=None\n",
    "        # print(f\"\\nĐang xử lý Trang {current_page_num}/{len(pdf_page_pil_images_list)}...\")\n",
    "        try:\n",
    "            cv_bgr_page_image = cv2.cvtColor(np.array(current_pil_image), cv2.COLOR_RGB2BGR)\n",
    "            if cv_bgr_page_image is None or cv_bgr_page_image.size == 0:\n",
    "                # print(f\"  Cảnh báo: Trang {current_page_num} rỗng. Bỏ qua.\"); \n",
    "                all_page_processing_results[current_page_num] = []; continue\n",
    "            image_to_process_for_saving = cv_bgr_page_image.copy()\n",
    "            if enable_pdf_page_deskew:\n",
    "                deskewed_page_version = deskew_page_basic(cv_bgr_page_image, pdf_page_deskew_angle_thresh)\n",
    "                image_to_process_for_saving = deskewed_page_version\n",
    "            temp_page_image_filename = f\"page_{current_page_num:03d}.png\"\n",
    "            temp_page_image_file_path = temp_pages_dir_obj / temp_page_image_filename\n",
    "            if not cv2.imwrite(str(temp_page_image_file_path), image_to_process_for_saving):\n",
    "                # print(f\"  Cảnh báo: Không thể lưu ảnh tạm cho trang {current_page_num}. Bỏ qua.\"); \n",
    "                all_page_processing_results[current_page_num] = []; continue\n",
    "            current_page_output_prefix = f\"{base_output_dir_prefix}_pg{current_page_num:03d}\"\n",
    "            saved_table_paths_for_this_page = detect_tables_cv_tt_combined(\n",
    "                page_image_path=temp_page_image_file_path, output_dir_prefix=current_page_output_prefix,\n",
    "                cv_detect_params=cv_detection_config_main, table_deskew_params=table_deskew_config_main,\n",
    "                iou_match_threshold=iou_matching_thresh_config, tt_page_confidence_threshold=tt_page_confidence_thresh_config_val,\n",
    "                tt_detection_model=tt_detection_model_loaded, tt_detection_processor=tt_detection_processor_loaded,\n",
    "                tt_structure_model=tt_structure_model_loaded, easyocr_reader=easyocr_reader_loaded\n",
    "            )\n",
    "            all_page_processing_results[current_page_num] = saved_table_paths_for_this_page\n",
    "            num_tables_on_this_page = len(saved_table_paths_for_this_page)\n",
    "            total_tables_extracted_count += num_tables_on_this_page\n",
    "            # print(f\"  Trang {current_page_num}: Tìm thấy và đã lưu {num_tables_on_this_page} bảng khớp tiêu chí.\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n!!! Người dùng đã ngắt xử lý trên trang {current_page_num}. Đang dừng.\")\n",
    "            shutil.rmtree(temp_pages_dir_obj, ignore_errors=True); raise\n",
    "        except Exception as e_process_page:\n",
    "            print(f\"  LỖI NGHIÊM TRỌNG khi xử lý trang {current_page_num}: {e_process_page}\")\n",
    "            import traceback; traceback.print_exc()\n",
    "            all_page_processing_results[current_page_num] = []\n",
    "        finally:\n",
    "            if temp_page_image_file_path and temp_page_image_file_path.exists():\n",
    "                try: os.remove(temp_page_image_file_path)\n",
    "                except OSError as e_remove_temp: print(f\"  Cảnh báo: Không thể xóa tệp trang tạm {temp_page_image_file_path}: {e_remove_temp}\")\n",
    "    shutil.rmtree(temp_pages_dir_obj, ignore_errors=True)\n",
    "    return all_page_processing_results, total_tables_extracted_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global yolo_model_global, TT_DETECTION_MODEL, TT_DETECTION_PROCESSOR, TT_STRUCTURE_MODEL, EASYOCR_READER # Để truy cập các model đã load\n",
    "\n",
    "    # Tham số cấu hình\n",
    "    CONFIG = {\n",
    "        \"PDF_DPI\":200,\n",
    "        \"ENABLE_PAGE_DESKEW\":True,\n",
    "        \"PAGE_DESKEW_ANGLE_THRESHOLD\":0.5,\n",
    "        \"CV_DETECT_PARAMS\":{\n",
    "            'min_line_ratio':0.015, 'min_area_ratio':0.005, 'min_dim_px':20,\n",
    "            'dilate_iter':2, 'padding':10, 'overlap_threshold_ratio':0.65\n",
    "        },\n",
    "        \"TABLE_DESKEW_PARAMS\":{\n",
    "            'morph_kernel_width_factor':0.12, 'morph_iterations':1, 'hough_threshold':20,\n",
    "            'hough_min_line_length_factor':0.15, 'hough_max_line_gap_factor':0.04,\n",
    "            'canny_low_thresh':40, 'canny_high_thresh':120, 'angle_filter_degrees':20.0,\n",
    "            'rotation_threshold_degrees':0.20\n",
    "        },\n",
    "        \"IOU_MATCH_THRESHOLD\":0.35,\n",
    "        \"TT_PAGE_CONFIDENCE_THRESHOLD\":0.9,\n",
    "        \"OUTPUT_BASE_DIR\":Path(\"./table_extraction_output_local\"), # Thay đổi đường dẫn output\n",
    "        \"TEMP_PDF_PAGES_DIR\":Path(\"./temp_pdf_pages_local\"),    # Thay đổi đường dẫn temp\n",
    "        \"YOLO_ENABLE_VALIDATION\":False,\n",
    "        \"YOLO_MODEL_PATH\":\"keremberke/yolov8n-table-detection\",\n",
    "    }\n",
    "\n",
    "    if CONFIG[\"YOLO_ENABLE_VALIDATION\"]:\n",
    "        try:\n",
    "            from ultralytics import YOLO # Đảm bảo import\n",
    "            yolo_model_global, _ = load_yolo_model_safe(CONFIG[\"YOLO_MODEL_PATH\"], yolo_device_global)\n",
    "            # if yolo_model_global: print(\"Mô hình YOLO đã tải (cho validation tùy chọn).\")\n",
    "        except ImportError:\n",
    "             print(\"Ultralytics chưa được cài. Không thể tải YOLO.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi tải YOLO: {e}\")\n",
    "\n",
    "\n",
    "    shutil.rmtree(CONFIG[\"OUTPUT_BASE_DIR\"],ignore_errors=True)\n",
    "    shutil.rmtree(CONFIG[\"TEMP_PDF_PAGES_DIR\"],ignore_errors=True)\n",
    "    # os.makedirs(CONFIG[\"OUTPUT_BASE_DIR\"],exist_ok=True)\n",
    "\n",
    "    root = Tk()\n",
    "    root.withdraw() # Ẩn cửa sổ Tkinter chính\n",
    "    uploaded_pdf_file_path_main = filedialog.askopenfilename(\n",
    "        title=\"Chọn một file PDF để xử lý\",\n",
    "        filetypes=[(\"PDF files\", \"*.pdf\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "    root.destroy() \n",
    "\n",
    "    if not uploaded_pdf_file_path_main:\n",
    "        sys.exit(\"Thực thi bị dừng: Không có PDF được cung cấp.\")\n",
    "    else:\n",
    "        uploaded_pdf_file_path_main = Path(uploaded_pdf_file_path_main)\n",
    "\n",
    "    if uploaded_pdf_file_path_main and uploaded_pdf_file_path_main.exists():\n",
    "        # Kiểm tra xem các model cần thiết đã được tải chưa\n",
    "        if not TT_DETECTION_MODEL or not TT_DETECTION_PROCESSOR or \\\n",
    "           not TT_STRUCTURE_MODEL or not EASYOCR_READER:\n",
    "            # print(\"Lỗi nghiêm trọng: Một hoặc nhiều model chính (Table Transformer Detection/Structure, EasyOCR) chưa được tải thành công.\")\n",
    "            # print(\"Vui lòng kiểm tra thông báo lỗi ở trên và đảm bảo các model có thể được tải về.\")\n",
    "            sys.exit(\"Thoát do thiếu model.\")\n",
    "\n",
    "        pdf_basename_val=uploaded_pdf_file_path_main.name\n",
    "        pdf_name_no_ext_val=uploaded_pdf_file_path_main.stem\n",
    "        current_pdf_output_base_prefix = str(CONFIG[\"OUTPUT_BASE_DIR\"] / pdf_name_no_ext_val)\n",
    "\n",
    "        processing_start_main_time = time.time()\n",
    "        try:\n",
    "            page_results_dict, total_tables_extracted_final_count = process_pdf_for_tables_pipeline(\n",
    "                pdf_file_path_main=uploaded_pdf_file_path_main,\n",
    "                base_output_dir_prefix=current_pdf_output_base_prefix,\n",
    "                pdf_processing_dpi=CONFIG[\"PDF_DPI\"],\n",
    "                enable_pdf_page_deskew=CONFIG[\"ENABLE_PAGE_DESKEW\"],\n",
    "                pdf_page_deskew_angle_thresh=CONFIG[\"PAGE_DESKEW_ANGLE_THRESHOLD\"],\n",
    "                cv_detection_config_main=CONFIG[\"CV_DETECT_PARAMS\"],\n",
    "                table_deskew_config_main=CONFIG[\"TABLE_DESKEW_PARAMS\"],\n",
    "                iou_matching_thresh_config=CONFIG[\"IOU_MATCH_THRESHOLD\"],\n",
    "                tt_page_confidence_thresh_config_val=CONFIG[\"TT_PAGE_CONFIDENCE_THRESHOLD\"],\n",
    "                temp_pdf_pages_dir_path=CONFIG[\"TEMP_PDF_PAGES_DIR\"],\n",
    "                # Truyền các model đã load\n",
    "                tt_detection_model_loaded=TT_DETECTION_MODEL,\n",
    "                tt_detection_processor_loaded=TT_DETECTION_PROCESSOR,\n",
    "                tt_structure_model_loaded=TT_STRUCTURE_MODEL,\n",
    "                easyocr_reader_loaded=EASYOCR_READER\n",
    "            )\n",
    "            processing_duration_main_sec = time.time() - processing_start_main_time\n",
    "        except KeyboardInterrupt: print(\"\\n!!! XỬ LÝ BỊ NGƯỜI DÙNG NGẮT !!!\")\n",
    "        except Exception as e_main_process:\n",
    "            print(f\"\\n!!! ĐÃ XẢY RA LỖI NGHIÊM TRỌNG: {e_main_process} !!!\")\n",
    "            import traceback; traceback.print_exc()\n",
    "        finally:\n",
    "            if SHOW_PROCESSING_IMAGES:\n",
    "                cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"\\nLỗi: Đường dẫn tệp PDF không hợp lệ hoặc tệp không tồn tại.\")\n",
    "\n",
    "    overall_script_duration_sec = time.time() - overall_start_time\n",
    "    # print(f\"\\nTổng thời gian thực thi script: {overall_script_duration_sec:.2f} giây. --- Kết thúc Script ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
